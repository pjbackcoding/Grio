<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interview Assistant</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        .controls {
            display: flex;
            justify-content: space-between;
            margin-bottom: 20px;
        }
        .conversation {
            margin-top: 20px;
            max-height: 400px;
            overflow-y: auto;
            padding: 15px;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            background-color: #f8f9fa;
        }
        .question {
            background-color: #e9ecef;
            padding: 10px 15px;
            border-radius: 5px;
            margin-bottom: 10px;
        }
        .answer {
            background-color: #d1e7dd;
            padding: 10px 15px;
            border-radius: 5px;
            margin-bottom: 10px;
            white-space: pre-wrap;
        }
        .separator {
            height: 10px;
            border-bottom: 1px dashed #adb5bd;
            margin-bottom: 20px;
        }
        .settings {
            margin-top: 20px;
            padding: 15px;
            border: 1px solid #dee2e6;
            border-radius: 5px;
        }
        .recording-indicator {
            display: inline-block;
            width: 15px;
            height: 15px;
            background-color: red;
            border-radius: 50%;
            margin-right: 10px;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Interview Assistant</h1>
            <p class="text-muted">Your AI-powered interview companion</p>
        </div>

        <div class="settings mb-4">
            <h5>Settings</h5>
            <div class="mb-3">
                <label for="jobRole" class="form-label">Job Role (optional)</label>
                <input type="text" class="form-control" id="jobRole" placeholder="e.g., Software Engineer, Marketing Manager">
            </div>
            <div class="mb-3">
                <label for="context" class="form-label">Additional Context (optional)</label>
                <textarea class="form-control" id="context" rows="2" placeholder="Add any additional context about your experience or the role"></textarea>
            </div>
            <div class="mb-3">
                <label for="language" class="form-label">Speech Recognition Language</label>
                <select class="form-control" id="language">
                    <option value="en-US">English (US)</option>
                    <option value="fr-FR">French (France)</option>
                    <option value="es-ES">Spanish (Spain)</option>
                    <option value="de-DE">German</option>
                    <option value="it-IT">Italian</option>
                    <option value="ja-JP">Japanese</option>
                    <option value="zh-CN">Chinese (Simplified)</option>
                </select>
            </div>
        </div>

        <div class="controls mb-3">
            <h5>Voice Controls</h5>
            <p class="text-muted">Speak your interview questions using your microphone</p>
            <div>
                <button id="startBtn" class="btn btn-primary">Start Listening</button>
                <button id="stopBtn" class="btn btn-danger" disabled>Stop Listening</button>
                <button id="clearBtn" class="btn btn-secondary">Clear Conversation</button>
            </div>
        </div>
        


        <div id="status" class="alert alert-info hidden">
            <span id="recordingIndicator" class="recording-indicator hidden"></span>
            <span id="statusText">Ready to start</span>
        </div>

        <div class="conversation" id="conversation">
            <div class="text-center text-muted">
                <p>Click "Start Listening" or upload an audio file to begin the interview</p>
            </div>
        </div>
    </div>

    <script>
        // DOM elements
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const clearBtn = document.getElementById('clearBtn');
        const status = document.getElementById('status');
        const statusText = document.getElementById('statusText');
        const recordingIndicator = document.getElementById('recordingIndicator');
        const conversation = document.getElementById('conversation');
        const jobRoleInput = document.getElementById('jobRole');
        const contextInput = document.getElementById('context');
        const languageSelect = document.getElementById('language');


        // Variables
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];
        let recognition;

        
        // Check if browser supports SpeechRecognition
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const hasSpeechRecognition = !!SpeechRecognition;

        // Initialize speech recognition if available
        if (hasSpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.continuous = true;  // Enable continuous mode
            recognition.interimResults = true;  // Show interim results
            // Set default language and update when changed
            recognition.lang = languageSelect.value;
            
            // Update recognition language when selection changes
            languageSelect.addEventListener('change', function() {
                recognition.lang = this.value;
                
                // If we're currently recording, restart recognition with new language
                if (isRecording) {
                    try {
                        recognition.stop();
                        setTimeout(() => recognition.start(), 300);
                        updateStatus(`Listening in ${getLanguageName(recognition.lang)}...`);
                    } catch (e) {
                        console.error('Error restarting recognition:', e);
                    }
                }
            });
            
            // Track if we're currently processing a question
            let isProcessing = false;
            // Buffer to collect interim results
            let currentTranscript = '';
            // Timeout to detect pauses between speaking
            let pauseTimeout = null;
            
            recognition.onresult = function(event) {
                // Get the latest result
                const resultIndex = event.resultIndex;
                const transcript = event.results[resultIndex][0].transcript;
                const isFinal = event.results[resultIndex].isFinal;
                
                // Show what's being heard
                if (!isFinal) {
                    updateStatus(`Listening (${getLanguageName(recognition.lang)}): ` + transcript);
                    currentTranscript = transcript;
                    
                    // Clear any existing timeout
                    if (pauseTimeout) clearTimeout(pauseTimeout);
                    
                    // Set a timeout to process after 1.5 seconds of silence
                    pauseTimeout = setTimeout(() => {
                        if (currentTranscript && !isProcessing) {
                            isProcessing = true;
                            processQuestion(currentTranscript, recognition.lang);
                            currentTranscript = '';
                        }
                    }, 1500);
                    
                } else if (!isProcessing) {
                    // If final result and not already processing
                    isProcessing = true;
                    if (pauseTimeout) clearTimeout(pauseTimeout);
                    processQuestion(transcript, recognition.lang);
                    currentTranscript = '';
                }
            };
            
            // Add event handler for when processing is complete
            window.addEventListener('processing-complete', function() {
                isProcessing = false;
                updateStatus('Listening...');
            });

            recognition.onerror = function(event) {
                console.error('Speech recognition error', event.error);
                updateStatus('Error recognizing speech. Please try again.');
                if (event.error === 'no-speech') {
                    // Don't stop for no-speech errors in continuous mode
                    return;
                }
                stopRecording();
            };

            recognition.onend = function() {
                // Always restart if recording is active
                if (isRecording) {
                    recognition.start();
                }
            };
        }

        // Event listeners
        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);
        clearBtn.addEventListener('click', clearConversation);


        // Functions
        // Helper function to get human-readable language name
        function getLanguageName(languageCode) {
            const languages = {
                'en-US': 'English',
                'fr-FR': 'French',
                'es-ES': 'Spanish',
                'de-DE': 'German',
                'it-IT': 'Italian',
                'ja-JP': 'Japanese',
                'zh-CN': 'Chinese'
            };
            return languages[languageCode] || languageCode;
        }
        
        function startRecording() {
            if (!hasSpeechRecognition) {
                updateStatus('Speech recognition is not supported in your browser. Please use the file upload option instead.');
                return;
            }
            
            // Reset any existing recognition state
            if (recognition) {
                try {
                    recognition.stop();
                } catch (e) {
                    // Ignore errors from stopping when not started
                }
            }

            isRecording = true;
            startBtn.disabled = true;
            stopBtn.disabled = false;
            status.classList.remove('hidden');
            recordingIndicator.classList.remove('hidden');
            
            // Use current language selection
            recognition.lang = languageSelect.value;
            updateStatus(`Listening in ${getLanguageName(recognition.lang)} (continuous mode)...`);

            // Start after a short delay to ensure previous instances are cleaned up
            setTimeout(() => {
                try {
                    recognition.start();
                } catch (e) {
                    console.error('Error starting recognition:', e);
                    updateStatus('Error starting speech recognition. Please try again.');
                    stopRecording();
                }
            }, 300);
        }

        function stopRecording() {
            isRecording = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
            recordingIndicator.classList.add('hidden');
            updateStatus('Stopped listening');

            if (recognition) {
                try {
                    recognition.stop();
                } catch (e) {
                    // Ignore errors from stopping when not started
                }
            }
        }

        function updateStatus(message) {
            statusText.textContent = message;
            status.classList.remove('hidden');
        }

        function processQuestion(question, lang) {
            // Add question to conversation
            addQuestionToConversation(question);
            
            // Update status
            updateStatus('Generating response...');
            
            // Get job role and context
            const jobRole = jobRoleInput.value.trim();
            const context = contextInput.value.trim();
            const language = lang || languageSelect.value;
            
            // Generate response
            fetch('/api/generate-response', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    question: question,
                    job_role: jobRole,
                    context: context,
                    language: language
                }),
            })
            .then(response => response.json())
            .then(data => {
                if (data.error) {
                    updateStatus(`Error: ${data.error}`);
                } else {
                    addAnswerToConversation(data.answer);
                    updateStatus('Listening...');
                    
                    // Dispatch event to signal processing is complete
                    window.dispatchEvent(new CustomEvent('processing-complete'));
                }
            })
            .catch(error => {
                console.error('Error:', error);
                updateStatus('Error generating response. Please try again.');
            });
        }

        function addQuestionToConversation(question) {
            const questionDiv = document.createElement('div');
            questionDiv.className = 'question';
            questionDiv.innerHTML = `<strong>Question:</strong> ${question}`;
            conversation.appendChild(questionDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }

        function addAnswerToConversation(answer) {
            const answerDiv = document.createElement('div');
            answerDiv.className = 'answer';
            answerDiv.innerHTML = `<strong>Answer:</strong> ${answer}`;
            conversation.appendChild(answerDiv);
            
            // Add a visual separator
            const separator = document.createElement('div');
            separator.className = 'separator';
            conversation.appendChild(separator);
            
            // Ensure scroll to the bottom of new content
            setTimeout(() => {
                conversation.scrollTop = conversation.scrollHeight;
            }, 100);
        }

        function clearConversation() {
            conversation.innerHTML = `
                <div class="text-center text-muted">
                    <p>Click "Start Listening" or upload an audio file to begin the interview</p>
                </div>
            `;
            updateStatus('Conversation cleared');
            
            // Reset recording state if active
            if (isRecording) {
                stopRecording();
                setTimeout(() => {
                    startRecording();
                }, 500);
            }
        }


        
        // Initialize
        updateStatus('Ready to start');
    </script>
</body>
</html>
